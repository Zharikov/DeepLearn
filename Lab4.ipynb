{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\python36\\lib\\site-packages\\IPython\\core\\magics\\pylab.py:160: UserWarning: pylab import has clobbered these variables: ['time']\n",
      "`%matplotlib` prevents importing * from pylab and numpy\n",
      "  \"\\n`%matplotlib` prevents importing * from pylab and numpy\"\n"
     ]
    }
   ],
   "source": [
    "#https://www.analyticsvidhya.com/blog/2018/06/unsupervised-deep-learning-computer-vision/\n",
    "%pylab inline\n",
    "import os\n",
    "import keras\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import keras.backend as K\n",
    "from keras import regularizers\n",
    "\n",
    "\n",
    "from time import time\n",
    "from sklearn.cluster import KMeans\n",
    "from keras import callbacks\n",
    "from keras.models import Model\n",
    "from keras.optimizers import SGD\n",
    "from keras.layers import Dense, Input\n",
    "from keras.initializers import VarianceScaling\n",
    "from keras.engine.topology import Layer, InputSpec\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "fashion_mnist = keras.datasets.fashion_mnist\n",
    "\n",
    "(train_x, train_y), (val_x, val_y) = fashion_mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_names = ['T-shirt/top', 'Trouser', 'Pullover', 'Dress', 'Coat', \n",
    "               'Sandal', 'Shirt', 'Sneaker', 'Bag', 'Ankle boot']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['T-shirt/top', 'Trouser', 'Pullover', 'Dress', 'Coat', 'Sandal', 'Shirt', 'Sneaker', 'Bag', 'Ankle boot']\n"
     ]
    }
   ],
   "source": [
    "print(class_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x = train_x/255.\n",
    "val_x = val_x/255.\n",
    "\n",
    "train_x = train_x.reshape(-1, 784)\n",
    "val_x = val_x.reshape(-1, 784)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "input_img = Input(shape=(784,))\n",
    "\n",
    "# суть в том, что пытаемся заюзать меньше битов \n",
    "encoded = Dense(2000, activation='relu')(input_img)\n",
    "encoded = Dense(500, activation='relu',\n",
    "                activity_regularizer=keras.regularizers.l1(10e-10))(encoded)\n",
    "encoded = Dense(500, activation='relu',\n",
    "                activity_regularizer=keras.regularizers.l1(10e-10))(encoded)\n",
    "# слой с выходом равным количеству классов\n",
    "encoded = Dense(10, activation='sigmoid',\n",
    "                activity_regularizer=keras.regularizers.l1(10e-10))(encoded)\n",
    "\n",
    "# восстановление с потерями входного сигнала \n",
    "decoded = Dense(500, activation='relu')(encoded)\n",
    "decoded = Dense(500, activation='relu')(decoded)\n",
    "decoded = Dense(2000, activation='relu')(decoded)\n",
    "decoded = Dense(784)(decoded)\n",
    "\n",
    "# this model maps an input to its reconstruction\n",
    "autoencoder = Model(input_img, decoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_3 (InputLayer)         (None, 784)               0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 2000)              1570000   \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 500)               1000500   \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 500)               250500    \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 10)                5010      \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 500)               5500      \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 500)               250500    \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 2000)              1002000   \n",
      "_________________________________________________________________\n",
      "dense_10 (Dense)             (None, 784)               1568784   \n",
      "=================================================================\n",
      "Total params: 5,652,794\n",
      "Trainable params: 5,652,794\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "autoencoder.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  this model maps an input to its encoded representation\n",
    "encoder = Model(input_img, encoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "autoencoder.compile(optimizer='adam', loss='mse')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "estop = keras.callbacks.EarlyStopping(monitor='val_loss', min_delta=0, patience=10, verbose=1, mode='auto')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/5\n",
      "60000/60000 [==============================] - 45s 745us/step - loss: 0.0912 - val_loss: 0.0670\n",
      "Epoch 2/5\n",
      "60000/60000 [==============================] - 46s 768us/step - loss: 0.0583 - val_loss: 0.0482\n",
      "Epoch 3/5\n",
      "60000/60000 [==============================] - 44s 733us/step - loss: 0.0423 - val_loss: 0.0390\n",
      "Epoch 4/5\n",
      "60000/60000 [==============================] - 44s 730us/step - loss: 0.0373 - val_loss: 0.0357\n",
      "Epoch 5/5\n",
      "60000/60000 [==============================] - 45s 755us/step - loss: 0.0342 - val_loss: 0.0315\n"
     ]
    }
   ],
   "source": [
    "train_history = autoencoder.fit(train_x, train_x, epochs=5, batch_size=2048, validation_data=(val_x, val_x), callbacks=[estop])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10000, 784)\n"
     ]
    }
   ],
   "source": [
    "pred = autoencoder.predict(val_x)\n",
    "print(val_x.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Копия:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x1c09b7fa780>"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(pred[0].reshape(28, 28), cmap='gray')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Неповторимый оригинал"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x1c09b88ca20>"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4yLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvOIA7rQAAD3FJREFUeJzt3X+MVeWdx/HPVwRUfiiC4EBF2IrootFuJqJSN26qxd00wWow5S/Wmk5NatImNVnjPzXZNKmbtrvrP01oJKVJa9tEqaRZtiVms3aTjYrEoC22YDOUwREWQfkhiDN89485bEac8zx37j3nnst+36+EzL33e889D3fmM+fcec7zPObuAhDPBU03AEAzCD8QFOEHgiL8QFCEHwiK8ANBEX4gKMIPBEX4gaAu7ObOzIzLCYGaubu18ryOjvxmdo+Z/cHM9pjZY528FoDusnav7TezKZL+KOluSUOSXpG0zt1/n9iGIz9Qs24c+W+RtMfd/+TupyX9TNKaDl4PQBd1Ev5FkvaNuz9UPPYxZjZgZtvNbHsH+wJQsU7+4DfRqcUnTuvdfYOkDRKn/UAv6eTIPyTpqnH3PyXp7c6aA6BbOgn/K5KWmdlSM5sm6UuStlTTLAB1a/u0391HzOwRSb+WNEXSRnf/XWUtA1Crtrv62toZn/mB2nXlIh8A5y/CDwRF+IGgCD8QFOEHgiL8QFCEHwiK8ANBEX4gKMIPBEX4gaAIPxAU4QeCIvxAUIQfCIrwA0ERfiAowg8ERfiBoAg/EBThB4Ii/EBQhB8IivADQRF+ICjCDwRF+IGgCD8QFOEHgmp7iW5JMrNBScckjUoacff+KhoFoH4dhb/wN+5+qILXAdBFnPYDQXUafpf0GzN71cwGqmgQgO7o9LR/lbu/bWbzJW0zszfd/cXxTyh+KfCLAegx5u7VvJDZE5KOu/t3E8+pZmcASrm7tfK8tk/7zWyGmc06e1vS5yW90e7rAeiuTk77F0jabGZnX+en7v7vlbQKQO0qO+1vaWec9gO1q/20H8D5jfADQRF+ICjCDwRF+IGgCD8QVBWj+oBGTJkyJVk/c+ZMaa3TLu7p06cn6x9++GGyfs0115TW9uzZ01abJosjPxAU4QeCIvxAUIQfCIrwA0ERfiAowg8ERT9/cMV8DG3XU33pkrRo0aLS2m233ZbcduvWrcn6iRMnkvU65frxc+6///7S2pNPPtnRa7eKIz8QFOEHgiL8QFCEHwiK8ANBEX4gKMIPBEU/P5Jy/fg5d9xxR2lt5cqVyW0XLlyYrD/11FNttakK8+fPT9ZXr16drB89erTK5rSFIz8QFOEHgiL8QFCEHwiK8ANBEX4gKMIPBJXt5zezjZK+IOmgu99QPHa5pJ9LWiJpUNID7n6kvmaiLrm570dGRpL1/v7+ZP36668vrR04cCC57bJly5L1zZs3J+uHDx8urV188cXJbffu3Zusz507N1mfPXt2sj40NJSsd0MrR/4fSbrnnMcek/SCuy+T9EJxH8B5JBt+d39R0rm/QtdI2lTc3iTp3orbBaBm7X7mX+Duw5JUfE1f6wig59R+bb+ZDUgaqHs/ACan3SP/ATPrk6Ti68GyJ7r7Bnfvd/f0X4YAdFW74d8iaX1xe72k56tpDoBuyYbfzJ6R9N+SlpvZkJk9JOk7ku42s92S7i7uAziPZD/zu/u6ktLnKm4LanDBBenf77l+/BkzZiTra9euTdZT89tfdNFFyW1nzZqVrOfWFEj933PbrlixIlnft29fsn7kSPqylwsvbH4qDa7wA4Ii/EBQhB8IivADQRF+ICjCDwTVfH/DeSLVNeTuyW1z3W257XP11LDc0dHR5LY5Dz/8cLL+zjvvJOunTp0qrS1ZsiS5ba4rMDckOPW+5KYkzy3/ffr06WQ9N6R3+vTppbVc92pVS5Nz5AeCIvxAUIQfCIrwA0ERfiAowg8ERfiBoML08+eGcHba157S6TLXuem1O+nLX7eubMT2mCuvvDJZ37FjR7I+derU0tpll12W3Pbdd99N1lNTc0vSvHnzSmu54cK59zwnd23HJZdcUlrLTVn+2muvtdWmc3HkB4Ii/EBQhB8IivADQRF+ICjCDwRF+IGgwvTzd9JPL6X7bXN9url++FzbOunHf/DBB5P15cuXJ+u5KapTfelS+vqK3DLZ+/fvT9ZzffWp6ys++OCD5La5uQQ6vW4kZfXq1ck6/fwAOkL4gaAIPxAU4QeCIvxAUIQfCIrwA0Fl+/nNbKOkL0g66O43FI89Iekrkv6neNrj7v5vdTXyrFx/ekqu3zXXb5vqM+50vH7OwoULk/X77ruvtJbrS9+9e3eyPnPmzGQ9Nf+8JM2dO7e0lpv7Pvc9S42Jz8ldO5FaWryV7XNz66d+ZlatWpXctiqtpOlHku6Z4PF/dvebi3+1Bx9AtbLhd/cXJaWnTAFw3unkM/8jZrbTzDaa2ZzKWgSgK9oN/w8kfVrSzZKGJX2v7IlmNmBm281se5v7AlCDtsLv7gfcfdTdz0j6oaRbEs/d4O797t7fbiMBVK+t8JtZ37i7X5T0RjXNAdAtrXT1PSPpTknzzGxI0rck3WlmN0tySYOSvlpjGwHUIBt+d59oYven291hJ2vJ19mf3sn46yuuuCJZv/rqq5P16667Llnv6+tL1lP95UePHk1um5s7P7fOfGpefil9HUDu+5l733L7fu+990prH330UXLbXNty15ycPHkyWU/l4NixY8ltV6xYUVp76623ktuOxxV+QFCEHwiK8ANBEX4gKMIPBEX4gaC6PnV3J9NQL1iwoLSW6xaaMWNGR/XU0NilS5cmt80NPc11Ox0/fjxZT3U7XXrppcltc0N+R0ZGkvXc/y01RXZu2Oy0adOS9eHh4WQ99X/PtfvIkSPJem6o85w56eEuqSG/uWXRU8Ok9+7dm9x2PI78QFCEHwiK8ANBEX4gKMIPBEX4gaAIPxBUTy3RfddddyXrqSmsc33l8+fPT9ZzQzRTQzxz+84N0cz1Gef6fVPTjuem1s71Z+fel1zbU0NXc9Nb5963999/P1nPfc87kXvfckOCU9dX5K5vSF17MZmh6Rz5gaAIPxAU4QeCIvxAUIQfCIrwA0ERfiCorvbzz549W7feemtp/aGHHkpu/+abb5bWcmO7c1NYp/qjpfT02Lltc3L92bl+39QcCbmpt3NLk+fG++f6s1PTa+euX0jN3yClp7DO7bvT71nuGoXcfAGnTp1q+7UPHjxYWsvNvzAeR34gKMIPBEX4gaAIPxAU4QeCIvxAUIQfCCrbz29mV0n6saQrJZ2RtMHd/9XMLpf0c0lLJA1KesDdk4OcT5w4oZdffrm0nroGQJJuvPHG0tqqVauS2+bk+kdTffGHDx9Obpur58al5/r5U331qTneJWn58uXJeq6/OncdQWp8+U033ZTcdufOncn64OBgsp6aHyI3z0EnS7ZL+Z+n/fv3l9Zy16Sk5lDIzb/wsee28JwRSd909+sl3Srpa2b2l5Iek/SCuy+T9EJxH8B5Iht+dx929x3F7WOSdklaJGmNpE3F0zZJureuRgKo3qQ+85vZEkmfkfSSpAXuPiyN/YKQVN+cSQAq1/K1/WY2U9Kzkr7h7kdz14SP225A0kBxu502AqhBS0d+M5uqseD/xN2fKx4+YGZ9Rb1P0oSjDdx9g7v3u3v/ZP4YAaBe2TTa2OH6aUm73P3740pbJK0vbq+X9Hz1zQNQF8t1aZjZZyX9VtLrGuvqk6THNfa5/xeSFkv6s6S17p7s0zKzzvpPEnJTSK9cuTJZv/baa5P122+/vbSWmyI61x2WWx4893Ep9T3MDbnNdUOmhlFL0rZt25L1rVu3ltZSw1qrsGXLltLa4sWLk9seOnQoWc8Nw87VU12BuaXLH3300dLayZMnNTo62tLn6+xnfnf/L0llL/a5VnYCoPfwIRwIivADQRF+ICjCDwRF+IGgCD8QVLafv9Kd1djPD2CMu7fUz8+RHwiK8ANBEX4gKMIPBEX4gaAIPxAU4QeCIvxAUIQfCIrwA0ERfiAowg8ERfiBoAg/EBThB4Ii/EBQhB8IivADQRF+ICjCDwRF+IGgCD8QFOEHgsqG38yuMrP/MLNdZvY7M/t68fgTZrbfzF4r/v1d/c0FUJXsoh1m1iepz913mNksSa9KulfSA5KOu/t3W94Zi3YAtWt10Y4LW3ihYUnDxe1jZrZL0qLOmgegaZP6zG9mSyR9RtJLxUOPmNlOM9toZnNKthkws+1mtr2jlgKoVMtr9ZnZTEn/Kenb7v6cmS2QdEiSS/pHjX00+HLmNTjtB2rW6ml/S+E3s6mSfiXp1+7+/QnqSyT9yt1vyLwO4QdqVtlCnWZmkp6WtGt88Is/BJ71RUlvTLaRAJrTyl/7Pyvpt5Jel3SmePhxSesk3ayx0/5BSV8t/jiYei2O/EDNKj3trwrhB+pX2Wk/gP+fCD8QFOEHgiL8QFCEHwiK8ANBEX4gKMIPBEX4gaAIPxAU4QeCIvxAUIQfCIrwA0FlJ/Cs2CFJe8fdn1c81ot6tW292i6JtrWryrZd3eoTuzqe/xM7N9vu7v2NNSChV9vWq+2SaFu7mmobp/1AUIQfCKrp8G9oeP8pvdq2Xm2XRNva1UjbGv3MD6A5TR/5ATSkkfCb2T1m9gcz22NmjzXRhjJmNmhmrxcrDze6xFixDNpBM3tj3GOXm9k2M9tdfJ1wmbSG2tYTKzcnVpZu9L3rtRWvu37ab2ZTJP1R0t2ShiS9Immdu/++qw0pYWaDkvrdvfE+YTP7a0nHJf347GpIZvZPkg67+3eKX5xz3P0feqRtT2iSKzfX1LaylaX/Xg2+d1WueF2FJo78t0ja4+5/cvfTkn4maU0D7eh57v6ipMPnPLxG0qbi9iaN/fB0XUnbeoK7D7v7juL2MUlnV5Zu9L1LtKsRTYR/kaR94+4PqbeW/HZJvzGzV81soOnGTGDB2ZWRiq/zG27PubIrN3fTOStL98x7186K11VrIvwTrSbSS10Oq9z9ryT9raSvFae3aM0PJH1aY8u4DUv6XpONKVaWflbSN9z9aJNtGW+CdjXyvjUR/iFJV427/ylJbzfQjgm5+9vF14OSNmvsY0ovOXB2kdTi68GG2/N/3P2Au4+6+xlJP1SD712xsvSzkn7i7s8VDzf+3k3UrqbetybC/4qkZWa21MymSfqSpC0NtOMTzGxG8YcYmdkMSZ9X760+vEXS+uL2eknPN9iWj+mVlZvLVpZWw+9dr6143chFPkVXxr9ImiJpo7t/u+uNmICZ/YXGjvbS2IjHnzbZNjN7RtKdGhv1dUDStyT9UtIvJC2W9GdJa9296394K2nbnZrkys01ta1sZemX1OB7V+WK15W0hyv8gJi4wg8IivADQRF+ICjCDwRF+IGgCD8QFOEHgiL8QFD/C/7zxfJ8JVHJAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(val_x[0].reshape(28, 28), cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Error when checking input: expected input_3 to have shape (784,) but got array with shape (10000,)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-41-3a6398c4add2>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;31m#train_y = train_y.reshape(-1, 784)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;31m#val_y = val_y.reshape(-1, 784)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m \u001b[0mscore\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mautoencoder\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_x\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m10000\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mval_x\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m10000\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      9\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'\\n'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'Test accuracy:'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mscore\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\python36\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mevaluate\u001b[1;34m(self, x, y, batch_size, verbose, sample_weight, steps)\u001b[0m\n\u001b[0;32m   1100\u001b[0m             \u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1101\u001b[0m             \u001b[0msample_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1102\u001b[1;33m             batch_size=batch_size)\n\u001b[0m\u001b[0;32m   1103\u001b[0m         \u001b[1;31m# Prepare inputs, delegate logic to `test_loop`.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1104\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_uses_dynamic_learning_phase\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\python36\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36m_standardize_user_data\u001b[1;34m(self, x, y, sample_weight, class_weight, check_array_lengths, batch_size)\u001b[0m\n\u001b[0;32m    749\u001b[0m             \u001b[0mfeed_input_shapes\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    750\u001b[0m             \u001b[0mcheck_batch_axis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m  \u001b[1;31m# Don't enforce the batch size.\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 751\u001b[1;33m             exception_prefix='input')\n\u001b[0m\u001b[0;32m    752\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    753\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0my\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\python36\\lib\\site-packages\\keras\\engine\\training_utils.py\u001b[0m in \u001b[0;36mstandardize_input_data\u001b[1;34m(data, names, shapes, check_batch_axis, exception_prefix)\u001b[0m\n\u001b[0;32m    136\u001b[0m                             \u001b[1;34m': expected '\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mnames\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m' to have shape '\u001b[0m \u001b[1;33m+\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    137\u001b[0m                             \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m' but got array with shape '\u001b[0m \u001b[1;33m+\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 138\u001b[1;33m                             str(data_shape))\n\u001b[0m\u001b[0;32m    139\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    140\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Error when checking input: expected input_3 to have shape (784,) but got array with shape (10000,)"
     ]
    }
   ],
   "source": [
    "# Оценим модель по тестовому набору \n",
    "#train_y = train_y/255.\n",
    "#val_y = val_y/255.\n",
    "#print(train_y.shape)\n",
    "#print(val_y.shape)\n",
    "#train_y = train_y.reshape(-1, 784)\n",
    "#val_y = val_y.reshape(-1, 784)\n",
    "score = autoencoder.evaluate(train_x.reshape(-1, 10000), val_x.reshape(-1, 10000), verbose=0)\n",
    "print('\\n', 'Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
